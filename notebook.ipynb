{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array1 -= np.min(image_array1)\n",
    "image_array1 = (image_array1) / (np.max(image_array1) - np.min(image_array1)) * 255\n",
    "# image_array1 = image_array1.astype(np.uint8)\n",
    "\n",
    "# cv2.imwrite('test1.jpg', image_array1)\n",
    "# cv2.imwrite('test2.jpg', image_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900)\n",
      "255.0\n",
      "0.0\n",
      "809999\n",
      "24.120798\n"
     ]
    }
   ],
   "source": [
    "print(image_array1.shape)\n",
    "print(np.max(image_array1))\n",
    "print(np.min(image_array1))\n",
    "print(np.count_nonzero(image_array1))\n",
    "print(np.mean(image_array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(filename='test5.jpg', img=image_array1)\n",
    "# Image.fromarray(image_array1).save(fp='test3.jpg', format='JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_image = Image.open(fp='/home/msis/Work/dataset/MVTec_AD/bottle/test/broken_large/000.png', mode='r')\n",
    "ground_truth = Image.open(fp='/home/msis/Work/dataset/MVTec_AD/bottle/ground_truth/broken_large/000_mask.png', mode='r')\n",
    "ground_truth = cv2.cvtColor(src=np.array(ground_truth), code=cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "concated = np.concatenate([original_image, ground_truth], axis=1)\n",
    "\n",
    "cv2.imwrite(filename='z2.png', img=concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900)\n",
      "(900, 900, 3)\n"
     ]
    }
   ],
   "source": [
    "print(original_image.size)\n",
    "print(ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8782, 0.8586, 0.4214, 0.8382, 0.3871, 0.6745, 0.6527, 0.6124, 0.5187,\n",
      "        0.4913], dtype=torch.float64) \n",
      "\n",
      "torch.return_types.sort(\n",
      "values=tensor([0.3871, 0.4214, 0.4913, 0.5187, 0.6124, 0.6527, 0.6745, 0.8382, 0.8586,\n",
      "        0.8782], dtype=torch.float64),\n",
      "indices=tensor([4, 2, 9, 8, 7, 6, 5, 3, 1, 0]))\n",
      "tensor(0.8586, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from numpy import random\n",
    "\n",
    "arr = random.rand(10)\n",
    "arr2 = torch.tensor(arr)\n",
    "print(arr2, '\\n')\n",
    "print(arr2.sort())\n",
    "\n",
    "quant = torch.quantile(arr2, 8/9)\n",
    "print(quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{output}{i,j,k} = \\frac{\\text{input}{i,j,k} - \\text{mean}_i}{\\text{std}_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mvtec_ad import MVTecAD\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(transforms=[ transforms.Resize(size=(300, 300)),\n",
    "                                            transforms.ToTensor()   ])\n",
    "target_transform = transforms.Lambda(lambd=lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/msis/Work/dataset/MVTec_AD'\n",
    "category = 'grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose(transforms=[\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_transform = transforms.Compose(transforms=[\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MVTecAD(root=root_dir,\n",
    "                        category=category,\n",
    "                        train=True,\n",
    "                        transform=image_transform,\n",
    "                        target_transform=target_transform,\n",
    "                        mask_transform=mask_transform,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MVTecAD(root=root_dir,\n",
    "                       category=category,\n",
    "                       train=False,\n",
    "                       transform=image_transform,\n",
    "                       mask_transform=mask_transform,\n",
    "                       pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=1,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Batch 1:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([1])\n",
      "Batch 2:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([1])\n",
      "Batch 3:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\")\n",
    "for batch_idx, (images, masks, targets) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"  Images shape: {images.shape}\")\n",
    "    print(f\"  Masks shape: {masks.shape}\")\n",
    "    print(f\"  Targets: {targets}\")\n",
    "    if batch_idx == 2:  # Show only first 3 batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data:\n",
      "Batch 1:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([0])\n",
      "Batch 2:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([0])\n",
      "Batch 3:\n",
      "  Images shape: torch.Size([1, 3, 256, 256])\n",
      "  Masks shape: torch.Size([1, 1, 256, 256])\n",
      "  Targets: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the testing data\n",
    "print(\"\\nTesting data:\")\n",
    "for batch_idx, (images, masks, targets) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"  Images shape: {images.shape}\")\n",
    "    print(f\"  Masks shape: {masks.shape}\")\n",
    "    print(f\"  Targets: {targets}\")\n",
    "    if batch_idx == 2:  # Show only first 3 batches\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficientad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
